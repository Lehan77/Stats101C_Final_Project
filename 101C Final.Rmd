---
title: "STATS 101C PRJKT"
output:
  pdf_document: default
  html_document: default
---
```{r}
library(nnet)
library(randomForest)
library(caret)
library(e1071)
library(MASS)
```

# 1. Data preprocessing

```{r}
# remove id and index
data <- read.csv("Data_Final.csv", na.strings="")
data <- data[,c(-1,-2,-3,-9,-10,-16)]
data <- na.omit(data)
```

```{r}
clean_review = function(x){
  x <- gsub("\n"," ",x) # remove new lines
  x <- gsub(","," ",x) # remove ","
  x <- gsub("!","",x) # remove "!"
  x <- gsub("\\.","",x) # remove "."
  x <- tolower(x) # transform all capitals to lower letters
  x
}
data$Review <- clean_review(data$Review)
```


# 2. Build sentiment dictionary

```{r}
pos_word <- read.table("positive-words.txt")$V1
neg_word <- read.table("negative-words.txt")$V1
all_word <- c(pos_word,neg_word)

get_review_dict <- function(x){
  x <- strsplit(x," ")[[1]]
  out <- logical(0)
  pos_num <- 0
  neg_num <- 0
  for(word in x){ # count positive words
    if(word %in% pos_word){
      pos_num <- pos_num + 1
    }
    else if(word %in% neg_word){ # count positive words
      neg_num <- neg_num +1
    }
  }
  c(pos_num,neg_num,length(x)) # positive words amount, negative words amount, all words amount
}

for(i in 1:dim(data)[1]){
  out <- get_review_dict(data[i,"Review"])
  if(i == 1){
    all_dict <- out
  }
  else{
    all_dict <- cbind(all_dict, out)
  }
}
scores <- as.data.frame(t(all_dict))
colnames(scores) <- c("pos","neg","length") # create new columns
data <- cbind(data,scores) 
data <- data[, -5] # remove the review column
```

# 3.Select features using random forest

```{r}
data$Star <- as.factor(data$Star) # transform into factor so we can build random forest
rf <- randomForest(Star~., data = data, ntree = 500, importance = T) # build random forest with n = 500
plot(rf,main = "Error Rate vs Number of Trees") # draw a plot to see if number of trees differs significantly, and the result shows that n = 100 is good enough
rf <- randomForest(Star~., data = data, ntree = 100, importance = T) # through testing, it takes a lot more time to run random forest with 500 trees, so we choose n = 100 to reduce computational expense
imp <- data.frame(importance(rf)) # calculate importance so we can decide which features to use
imp <- imp[order(imp$MeanDecreaseAccuracy, decreasing = TRUE), ] # sort by Mean Decrease Accuracy
print(imp)
select_feature <- rownames(imp)[1:5] # select the top 5 most important predictors
data <- data[,c("Star", select_feature)]

varImpPlot(rf, type = 1, scale = F) # ...or we can just use the graph to see which predictors are the most important ones, much simpler
```

Write out the selected data:

```{r}
write.csv(data,"Data_select.csv")
```

# 4. Build model and do validation

```{r}
data <- read.csv("Data_select.csv")

leave_one_out <- function(x, model_name){ # use LOOCV to select the best model within each method
 fold_num <- 5
 scores <- logical(0)
 f <- createMultiFolds(c(1:nrow(x)), k = fold_num, times = 1)
 for(i in 1:fold_num){
   train_ind <- f[[i]]
   train_data <- x[train_ind, ]
   valid_data <- x[-train_ind, ]
   if(model_name == "logistic"){
    model <- multinom(Star~., data = train_data) # Multinational Logistic
    y_pred <- predict(model, valid_data)
   }
   else if(model_name == "lda"){
     model <- lda(Star~., data = train_data) # LDA
     y_pred <- predict(model, valid_data)$class
   }
   else if(model_name == "qda"){
     model <- qda(Star~., data = train_data) # QDA
     y_pred <- predict(model, valid_data)$class
   }
   y_true <- valid_data[,"Star"]
   y_pred <- as.numeric(y_pred)
   y_true <- as.numeric(y_true)
   mse <- sum((y_pred-y_true)^2) / length(y_pred)
   scores <- c(scores, mse)
   }
 scores
 }

```

We calculate the mean "score", which is the mean squared error for each method, and select the smallest one.

```{r}
logistic_score <- leave_one_out(data,"logistic") # assign scores for Multinational Logistic regression
lda_score <- leave_one_out(data,"lda") # assign scores for LDA
qda_score <- leave_one_out(data,"qda") # assign scores for QDA
```

```{r}
cat("logistic_mse: ",mean(logistic_score),"\n")
cat("lda_mse: ",mean(lda_score),"\n")
cat("qda_mse: ",mean(qda_score),"\n")
```

Since the logistic prediction error is the smallest, the logistic model is selected.